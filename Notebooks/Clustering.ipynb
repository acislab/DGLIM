{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from peewee import *\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import pandas as pd\n",
    "import requests\n",
    "import math\n",
    "from datetime import datetime\n",
    "from Model import *\n",
    "import re # Regular Expression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.cluster as cluster\n",
    "from sklearn import preprocessing\n",
    "from scipy.cluster.vq import whiten\n",
    "\n",
    "import dglim\n",
    "from dglim import City\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = dglim.loadData('Master Dataset')\n",
    "tracts_df = dglim.loadData('Tracts Dataset')\n",
    "blocks_df = dglim.loadData('Blocks Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeSparse(column, df=master_df):\n",
    "    column_data = df[column]\n",
    "    sparse_df = pd.DataFrame(index=df.index)\n",
    "    labels = df[column].unique()\n",
    "    for label in labels:\n",
    "        sparse_df[column + \" - \" + label] = pd.Series(column_data == label).astype(int)\n",
    "    \n",
    "    return sparse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'categorical_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6f91743e51fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m }\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mall_numerical_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_features\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcategorical_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'categorical_features' is not defined"
     ]
    }
   ],
   "source": [
    "feature_data = {}\n",
    "\n",
    "# Positional data\n",
    "feature_data['Latitude'] = pd.DataFrame(master_df['Latitude'][abs(master_df['Latitude'] - City.latitude) < .2]).dropna()\n",
    "feature_data['Longitude'] = pd.DataFrame(master_df['Longitude'][abs(master_df['Longitude'] - City.longitude) < .2]).dropna()\n",
    "\n",
    "# Categorical data\n",
    "feature_data['Business Type'] = makeSparse('Business Type')\n",
    "feature_data['NAICS Type'] = makeSparse('NAICS Type')\n",
    "\n",
    "# Dates\n",
    "feature_data['Age'] = pd.DataFrame((master_df['Start Date'] - datetime.now()).rename('Age').apply(lambda x: x.days/365.25)).dropna()\n",
    "\n",
    "# Successfulness\n",
    "successLabelValues = {\n",
    "    'Very Successful' : 3,\n",
    "    'Somewhat Successful' : 2,\n",
    "    'Somewhat Unsuccessful' : 1,\n",
    "    'Very Unsuccessful' : 0\n",
    "}\n",
    "feature_data['Successfulness'] = pd.DataFrame(master_df['Successfulness'].map(successLabelValues)).dropna()\n",
    "\n",
    "# Financials\n",
    "df = pd.DataFrame((master_df['Revenue in 2016'] - master_df['Expenses in 2016']).rename('Profit in 2016')).dropna()\n",
    "feature_data['Profit in 2016'] = df\n",
    "\n",
    "df = pd.DataFrame((master_df['Revenue in 2017'] - master_df['Expenses in 2017']).rename('Profit in 2017')).dropna()\n",
    "feature_data['Profit in 2017'] = df\n",
    "\n",
    "# Copy simple numerical data\n",
    "feature_data['Number of Employees']  = pd.DataFrame(master_df['Number of Employees']).dropna()\n",
    "feature_data['Revenue in 2016']      = pd.DataFrame(master_df['Revenue in 2016']).dropna()\n",
    "feature_data['Expenses in 2016']     = pd.DataFrame(master_df['Expenses in 2016']).dropna()\n",
    "feature_data['Investment in 2016']   = pd.DataFrame(master_df['Investment in 2016']).dropna()\n",
    "feature_data['Revenue in 2017']      = pd.DataFrame(master_df['Revenue in 2017']).dropna()\n",
    "feature_data['Expenses in 2017']     = pd.DataFrame(master_df['Expenses in 2017']).dropna()\n",
    "feature_data['Investment in 2017']   = pd.DataFrame(master_df['Investment in 2017']).dropna()\n",
    "feature_data['Crimes Within 500m']   = pd.DataFrame(master_df['Crimes Within 500m']).dropna()\n",
    "feature_data['Distance to Bus Stop'] = pd.DataFrame(master_df['Distance to Bus Stop']).dropna()\n",
    "\n",
    "# Gather types of features\n",
    "all_features = set(feature_data.keys())\n",
    "\n",
    "all_categorical_features = {\n",
    "    'Business Type',\n",
    "    'NAICS Type',\n",
    "}\n",
    "\n",
    "all_numerical_features = all_features - all_categorical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_data['Profit in 2017']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do Some Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_kwds = {'alpha' : 0.25, 's' : 80, 'linewidths':0}\n",
    "\n",
    "# Generate random points\n",
    "# x = []\n",
    "# y = []\n",
    "# for i in range(0, 500):\n",
    "#     x.append(rnd.randn())\n",
    "#     y.append(rnd.randn())\n",
    "# data = np.array(zip(x, y))\n",
    "\n",
    "# latitude = [x for x in master_df['Latitude']] #if np.isfinite(x) and abs(x - 29.65) < .2 else np.nan) for x in master_df['Latitude']]\n",
    "# longitude = [x for x in master_df['Longitude']]# if np.isfinite(x) and abs(x - -82.32) < .2 else np.nan]\n",
    "# successfulness = [(4 - x) for x in master_df['Successfulness']]\n",
    "\n",
    "features = {\n",
    "#     'Latitude',\n",
    "#     'Longitude',\n",
    "#     'Business Type',\n",
    "#     'NAICS Type',\n",
    "    'Age',\n",
    "#     'Number of Employees',\n",
    "    'Successfulness',\n",
    "#     'Profit in 2016',\n",
    "    'Revenue in 2016',\n",
    "    'Expenses in 2016',\n",
    "#     'Investment in 2016',\n",
    "#     'Profit in 2017',\n",
    "    'Revenue in 2017',\n",
    "    'Expenses in 2017',\n",
    "#     'Investment in 2017',\n",
    "#     'Crimes Within 500m',\n",
    "#     'Distance to Bus Stop',\n",
    "}\n",
    "\n",
    "# Gather used features in a single dataset\n",
    "data_df = pd.DataFrame(index=master_df.index)\n",
    "for feature in features:\n",
    "    data_df = data_df.join(feature_data[feature])\n",
    "\n",
    "data_df = data_df.dropna()\n",
    "\n",
    "# Normalize data\n",
    "norm_data_df = data_df.copy()\n",
    "for feature in (features & all_numerical_features):\n",
    "    print \"Normalizing\", feature\n",
    "    norm_data_df[feature] = whiten(norm_data_df[feature].astype('float'))\n",
    "\n",
    "data = np.array(norm_data_df.as_matrix())\n",
    "\n",
    "print len(data_df), 'entries'\n",
    "#print 'Sample data entry:', data[0]\n",
    "\n",
    "if (len(features) == 1):\n",
    "    plt.scatter(data.T[0], data.T[0], c='b', **plot_kwds)\n",
    "else:\n",
    "    plt.scatter(data.T[0], data.T[1], c='b', **plot_kwds)\n",
    "\n",
    "frame = plt.gca()\n",
    "frame.axes.get_xaxis().set_visible(False)\n",
    "frame.axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shamelessly borrowed from online\n",
    "# def plot_clusters(data, algorithm, args, kwds):\n",
    "#     labels = algorithm(*args,**kwds).fit_predict(data)\n",
    "#     palette = sns.color_palette('deep', np.unique(labels).max() + 1)\n",
    "#     colors = [palette[x] if x >= 0 else (0.0, 0.0, 0.0) for x in labels]\n",
    "#     plt.scatter(data.T[0], data.T[1], c=colors, **plot_kwds)\n",
    "#     frame = plt.gca()\n",
    "#     frame.axes.get_xaxis().set_visible(False)\n",
    "#     frame.axes.get_yaxis().set_visible(False)\n",
    "#     plt.title('Clusters found by {}'.format(str(algorithm.__name__)), fontsize=24)\n",
    "    \n",
    "#     return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Input\n",
    "data = data\n",
    "algorithm = cluster.KMeans\n",
    "args = ()\n",
    "kwds = {'n_clusters':6}\n",
    "\n",
    "labels = algorithm(*args, **kwds).fit_predict(data)\n",
    "palette = sns.color_palette('deep', np.unique(labels).max() + 1)\n",
    "colors = [palette[x] if x >= 0 else (0.0, 0.0, 0.0) for x in labels]\n",
    "plt.scatter(data.T[0], data.T[1], c=colors, **plot_kwds)\n",
    "frame = plt.gca()\n",
    "frame.axes.get_xaxis().set_visible(False)\n",
    "frame.axes.get_yaxis().set_visible(False)\n",
    "plt.title('Clusters found by {}'.format(str(algorithm.__name__)), fontsize=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeCompactSeries(sparse_df, column, df=master_df):\n",
    "    compact_df = pd.DataFrame(index=df.index, columns=[column])\n",
    "    values = df[column].unique()\n",
    "    for value in values:\n",
    "        label = column + \" - \" + value\n",
    "        new_data = sparse_df[label].map({0: np.nan, 1: value}).dropna()\n",
    "        compact_df[column][new_data.index] = new_data\n",
    "\n",
    "    return compact_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(index=data_df.index)\n",
    "\n",
    "# Compact sparse data\n",
    "for feature in (all_categorical_features & features):\n",
    "    results_df[feature] = makeCompactSeries(data_df, feature)\n",
    "\n",
    "# Copy non-sparse data\n",
    "for feature in ((all_features & features) - all_categorical_features):\n",
    "    results_df[feature] = data_df[feature]\n",
    "\n",
    "# Include cluster labels\n",
    "results_df.insert(loc=0, column='Cluster', value=labels)\n",
    "\n",
    "results_df.sort_values('Cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_df['Cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_df.sort_values('Cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
